# 第四次实践课作业-Transformer中英翻译
**罗浩铭 PB21030838**

## 题目
修改课程中的代码，使其完成中英翻译（原代码是英中翻译） 同时，将encoder layer的个数设为4，将decoder layer的个数设为5 展示训练后的中英翻译结果




## 实验结果

| 实验组别 | best-loss |
| :------: | :-------: |
| baseline |   1.788   |


## 附：练习
#### 0. 看看原始数据长什么样？
略
#### 1. 把代码跑通（所有的图都是可以展示的，对于理解Transformer非常有用）(含Debug和非Debug)
略
#### 1.5 试试预训练模型 save/models/large_model.pt， 与你自己训的对比一下 
#### 2. 看一看建立的英文词典和中文词典长什么样，思考一下为什么要有 "UNK" "BOS" "EOS"
#### 3. word embedding后的词长什么样？
#### 4. 思考一下，为什么要加positional_embedding

